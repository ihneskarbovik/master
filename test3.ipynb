{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopefully bugfree code\n",
    "\n",
    "Just trying to replicate test2 without bugs, using jupiter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather data set and split in x and y\n",
    "def read_dataset(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.loc[:, ~df.columns.str.match('Unnamed')]\n",
    "    df = df.replace('DC', 1)\n",
    "    df = df.replace('LTE', 0)\n",
    "\n",
    "    X, y = df.drop('Mode', axis=1), df['Mode']\n",
    "    return X, y\n",
    "\n",
    "# splitting the data into time series that overlap\n",
    "def split_time_series(X, y):\n",
    "    tss = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "    for train_index, test_index in tss.split(X):\n",
    "        X_train, X_test = np.array(X.iloc[train_index, :]), np.array(X.iloc[test_index,:])\n",
    "        y_train, y_test = np.array(y.iloc[train_index]), np.array(y.iloc[test_index])\n",
    "\n",
    "    # reshaping y to match dimentions of X\n",
    "    y_train = y_train.reshape(len(y_train), 1)\n",
    "    y_test = y_test.reshape(len(y_test), 1)\n",
    "    # horizontally stack columns\n",
    "    trainingset = np.hstack((X_train, y_train))\n",
    "    testset = np.hstack((X_test, y_test))\n",
    "\n",
    "    return trainingset, testset\n",
    "\n",
    "def series_split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check to see if we are bwyond the data set\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def parallel_split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check to see if we are beyond the data set\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining what a vertical change is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if there has been a vertical handover\n",
    "def define_change(y):\n",
    "    new_y = []\n",
    "    for seq in y:\n",
    "        if 0 in seq and 1 in seq:\n",
    "            new_y.append(1)\n",
    "        else:\n",
    "            new_y.append(0)\n",
    "    return np.array(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for evaluating result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "def precision_recall(y_pred, y_true):\n",
    "    # Initialize true positives (TP), false positives (FP), and false negatives (FN)\n",
    "    tp, fp, fn =  0, 0, 0\n",
    "\n",
    "    # Loop through true and predicted labels to count TP, FP, and FN\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tp += 1\n",
    "        elif yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "        elif yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "\n",
    "    # Precision calculation\n",
    "    if tp + fp == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "\n",
    "    # Recall calculation\n",
    "    if tp + fn == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a \"multiple input multi-step output\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3864\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3465\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2920\n",
      "Loss Mean: 0.342\n",
      "Loss Standard Deviation: 0.039\n",
      "Accuracy Mean: 0.767\n",
      "Accuracy Standard Deviation: 0.123\n",
      "Precision Mean: 0.767\n",
      "Precision Standard Deviation: 0.123\n",
      "Recall Mean: 1.000\n",
      "Recall Standard Deviation: 0.000\n"
     ]
    }
   ],
   "source": [
    "# prepping the data\n",
    "X, y = read_dataset('datasets/test_sample_unique.csv')\n",
    "\n",
    "# splitting the data into training and testing data\n",
    "train, test = split_time_series(X, y)\n",
    "\n",
    "# choose number of steps in/out\n",
    "n_steps_in, n_steps_out = 10, 5\n",
    "\n",
    "# split in train/test and input/output\n",
    "X_train, y_train = series_split_sequences(train, n_steps_in, n_steps_out)\n",
    "X_test, y_test = series_split_sequences(test, n_steps_in, n_steps_out)\n",
    "y_test_changed = define_change(y_test)\n",
    "\n",
    "# number of features\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "losses, accuracies, recalls, precisions = [], [], [], []\n",
    "\n",
    "for _ in range(3):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=300, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(units=300, activation='relu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "    # Final evaluation of the model\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    y_pred = define_change(y_pred)\n",
    "    loss, acc = model.evaluate(X_test, y_test), accuracy(y_pred, y_test_changed)\n",
    "    prec, rec = precision_recall(y_pred, y_test_changed)\n",
    "    losses.append(loss)\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "print(f'Loss Mean: {np.mean(losses):.3f}')\n",
    "print(f'Loss Standard Deviation: {np.std(losses):.3f}')\n",
    "print(f'Accuracy Mean: {np.mean(accuracies):.3f}')\n",
    "print(f'Accuracy Standard Deviation: {np.std(accuracies):.3f}')\n",
    "print(f'Precision Mean: {np.mean(precisions):.3f}')\n",
    "print(f'Precision Standard Deviation: {np.std(precisions):.3f}')\n",
    "print(f'Recall Mean: {np.mean(recalls):.3f}')\n",
    "print(f'Recall Standard Deviation: {np.std(recalls):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action points\n",
    "- process new data set\n",
    "- try LSTM on the merged dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
